{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## MachineLearning 第一课作业\n",
    "\n",
    "####  作业提交说明：\n",
    "- 位置：作业文件统一放置于/0.Teacher/Exercise/ML/MachineLearning-1/下\n",
    "- 文件名：请先复制该notebook文件，并重新命名为(课程名)+(您姓名的全拼)，并按要求完成后保存\n",
    "- 时间：课程结束后的第二天前提交。\n",
    "- 注意：请勿抄袭，移动，修改，删除其他同学和原始空白的练习文件。\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简答题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.数据挖掘，机器学习工程师，算法工程师，数据科学家，这些酷酷的岗位名字是认真的？说说你的理解这些岗位实际在做些什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 数据挖掘:\n",
    "\n",
    "一般是指从大量的数据中通过算法搜索隐藏于其中知识的工程技术专业人员。这些知识可用使企业决策智能化，自动化，从而使企业提高工作效率，减少错误决策的可能性，以在激烈的竞争中处于不败之地。\n",
    "\n",
    "2) 机器学习工程师:\n",
    "机器学习工程师参与软件架构和设计，他们也了解A / B测试的做法。但更重要的是，他们不仅仅是“了解”A / B测试，他们还知道如何在生产系统上进行A / B测试。他们了解日志和安全性等相关的问题；他们知道如何使日志数据对数据工程师有用。这里没有什么是特别新的东西：这是角色的深化，而不是变化。\n",
    "\n",
    "\n",
    "3) 算法工程师\n",
    "\n",
    "所谓算法工程师，首先需要是一名工程师，那么就要掌握所有开发工程师都需要掌握的一些能力。有些同学对于这一点存在一些误解，认为所谓算法工程师就只需要思考和设计算法，不用在乎这些算法如何实现，而且会有人帮你来实现你想出来的算法方案。这种思想是错误的，在大多数企业的大多数职位中，算法工程师需要负责从算法设计到算法实现再到算法上线这一个全流程的工作\n",
    "\n",
    "4) 数据科学家\n",
    "\n",
    "数据科学家是指能采用科学方法、运用数据挖掘工具对复杂多量的数字、符号、文字、网址、音频或视频等信息进行数字化重现与认识，并能寻找新的数据洞察的工程师或专家(不同于统计学家或分析师)。一个优秀的数据科学家需要具备的素质有：懂数据采集、懂数学算法、懂数学软件、懂数据分析、懂预测分析、懂市场应用、懂决策分析等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.常见的机器学习任务有哪几大类别，具体说说每个类别又有哪些应用？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 有监督学习:数据由记录、标记对组成。有监督学习算法分析数据，并产生一个推断的功能，用于映射新的数据。 \n",
    "2. 无监督学习：数据仅由记录组成。根据类别未知数据分析发现模式识别中的数据结构。\n",
    "3. 强化学习：用于描述和解决智能体在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.机器学习的学习任务大致可分为有监督学习与无监督学习，请说明如何区分以及各自的应用方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归方法任务\n",
    "\n",
    "回归方法是一种对数值型连续随机变量进行预测和建模的监督学习算法，也就是根据之前的数据建模，然后根据新的输入预测出一个准确的输出值。使用案例一般包括房价预测、股票走势或测试成绩等连续变化的案例。回归任务的特点是标注的数据集具有数值型的目标变量。也就是说，每一个观察样本都有一个数值型的标注真值以监督算法。\n",
    "\n",
    "分类方法任务  \n",
    "\n",
    "分类方法是一种对离散型随机变量建模或预测的监督学习算法，也就是将事物打上一个标签。使用案例包括邮件过滤、金融欺诈和预测雇员异动等输出为类别的任务。许多回归算法都有与其相对应的分类算法，分类算法通常适用于预测一个类别（或类别的概率）而不是连续的数值。\n",
    "\n",
    "聚类方法任务\n",
    "\n",
    "聚类是一种无监督学习任务，该算法基于数据的内部结构寻找观察样本的自然族群（即集群）。使用案例包括细分客户、新闻聚类、文章推荐等。 因为聚类是一种无监督学习（即数据没有标注），并且通常使用数据可视化评价结果。如果存在「正确的回答」（即在训练集中存在预标注的集群），那么分类算法可能更加合适。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.列举你所知道的机器学习任务中的一些术语并给出解释。（例如，特征，标签，训练等）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 标签\n",
    "标签是我们要预测的事物，即简单线性回归中的 y 变量。对于一个预测香港赛马比赛的机器学习模型而言，标签可以是某一次比赛的名次、获得奖金池的大小等。\n",
    "\n",
    "##### 特征\n",
    "特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征。对于预测香港赛马比赛的机器学习模型而言，特征包括了马的年龄、历史上曾经获得的名次、骑师历史上获得过的名次等几百个甚至几千个特征。\n",
    "\n",
    "##### 样本\n",
    "样本是指数据的特定实例。样本可以分为两类：一、有标签样本，二、无标签样本。有标签样本同时包含特征和标签。把香港跑马比赛历史数据拿来，给每一次比赛加上标签，得到的就是一个有标签样本，否则就是一个无标签样本。\n",
    "\n",
    "##### 模型\n",
    "模型定义了特征与标签之间的关系。例如一个预测香港赛马的模型可能会将某些马和骑师的特征与“赢得比赛前三名”紧密联系起来。\n",
    "\n",
    "##### 训练\n",
    "训练表示创建或学习模型。通过向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。把香港跑马比赛的历史数据切出一部分，作为训练数据集输入到模型中，让模型学习马与骑师的特征与跑马比赛的名次之间的关系，这个过程就是训练。\n",
    "\n",
    "##### 推断/预测\n",
    "推断表示将训练后的模型应用于无标签样本。也就是说，您使用训练后的模型来做出有用的预测 (y')。例如香港跑马比赛的模型，在训练好之后，把新的赛程信息传入到模型中，由。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.如何理解假设空间和参数空间？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设空间是由满足特征、预测映射的决策函数组成的集合。\n",
    "假设空间$\\mathcal{F}$定义为决策函数的集合\n",
    "$$\\mathcal{F} = \\left\\{ f | Y = f \\left( \\mathbf{X} \\right) \\right\\}$$\n",
    "其中，$\\mathbf{X}$是定义在输入空间$\\mathcal{X}$上的变量，$\\mathbf{X}\\in\\mathcal{X}$;$Y$是定义在输出空间$\\mathcal{Y}$上的变量。\n",
    "参数空间是由决定决策函数族的参数组成的空间。\n",
    "假设空间$\\mathcal{F}$通常是由一个参数向量决定的函数族\n",
    "$$\\mathcal{F} = \\left\\{ f | Y = f_{\\mathbf{w}} \\left( \\mathbf{X} \\right), \\mathbf{w} \\in \\mathbb{R}^{n} \\right\\} $$\n",
    "其中，参数向量$\\mathbf{w}$取值于$n$维向量空间$\\mathbb{R}^{n}$，称为参数空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.什么是损失函数？请写出回归任务中的均方误差的数学公式，并解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子\n",
    "\n",
    "回归任务中的均方误差的数学公式(MSE)\n",
    "\n",
    "$$MSE = \\frac{1}{N}\\sum_{i=1}^N ( x_i - \\widehat{x}_i )^{2}$$\n",
    "\n",
    "其中$N$是数据样本数，$x_i$是第$i$个数据样板的真实值，$\\widehat{x}_i$是第$i$个数据点的观测值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.如何理解欠拟合和过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过拟合：学习时选择的模型所包含的参数过多，以至于出现对已知数据预测得很好，但对未知数据预测得很差的现象。  \n",
    "欠拟合：学习时选择的模型所包含的参数过少，以至于出现不能对数据预测很好的现象。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.模型的泛化能力是指？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "泛化能力：学习得到的模型对未知数据的预测能力。   \n",
    "在实际中如果对训练数据能很好的拟合，而对验证集的效果较差，泛化能力较弱，可能出现过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请给出查准率与查全率的公式和解释。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例(true positive)、假正例(false positive)、真反例(true negative)、假反例(false negative)四种情形，令TP、FP、TN、FN分别表示其对应的样例数，则显然有TP+FP+TN+FN=样例总数。分类结果的“混淆矩阵”(confusion matrix)如表1所示。\n",
    "<table cellspacing=\"0\" cellpadding=\"0\" style=\"width:670px;color:rgb(62,62,62);font-family:'Helvetica Neue', Helvetica, 'Hiragino Sans GB', 'Microsoft YaHei', Arial, sans-serif;font-size:16px;background-color:rgb(255,255,255);\"><tbody><tr><td rowspan=\"2\" valign=\"top\"><p style=\"clear:both;min-height:1em;text-align:center;\">真实情况</p></td><td colspan=\"2\" valign=\"top\" style=\"border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">预测结果</p></td></tr><tr><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">正例</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">反例</p></td></tr><tr><td valign=\"top\" style=\"border-top:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">正例</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">TP(真正例)</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">FN(假反例)</p></td></tr><tr><td valign=\"top\" style=\"border-top:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">反例</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">FP(假正例)</p></td><td valign=\"top\" style=\"border-top:none;border-left:none;\"><p style=\"clear:both;min-height:1em;text-align:center;\">TN(真反例)</p></td></tr></tbody></table>\n",
    "查准率(Precision)，又叫准确率，缩写表示用P。查准率是针对我们预测结果而言的，它表示的是预测为正的样例中有多少是真正的正样例。定义公式如下\n",
    "\n",
    "$ P=\\frac{TP}{TP+FP} $\n",
    "\n",
    "查全率(Recall)，又叫召回率，缩写表示用R。查全率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确。定义公式如下\n",
    "\n",
    "$ P=\\frac{TP}{TP+FN} $\n",
    "\n",
    "查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。\n",
    "\n",
    "我们可以这样理解，在一个分类器中，你想要更高的查准率，那么你的阈值要设置的更高，只有这样才能有较高的把握确定我们预测是正例是真正例。一旦我们把阈值设置高了，那我们预测出正例的样本数就少了，那真正例数就更少了，查不全所有的正样例。\n",
    "\n",
    "举个例子来理解一下吧！例如，若希望将好瓜尽可能多地挑选出来，则可通过增加选瓜的数量来实现，如果将所有的西瓜都选上，那么所有的好瓜也必然都选上了，但这样查准率就会较低；若希望选出的瓜中好瓜比例尽可能高，则可只挑选最有把握的瓜，但这样就难免会漏掉不少好瓜，使得查全率较低。通常只有在一些简单任务中，才可能使查全率和查准率都很高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.正则化项是如何起到提高模型泛化能力作用的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正则化是为了解决过拟合问题\n",
    "\n",
    "\n",
    "机器学习中几乎都可以看到损失函数后面会添加一个额外项，常用的额外项一般有两种，一般英文称作ℓ1-norm和ℓ2-norm，中文称作L1正则化和L2正则化，或者L1范数和L2范数。\n",
    "\n",
    "L1正则化和L2正则化可以看做是损失函数的惩罚项。所谓『惩罚』是指对损失函数中的某些参数做一些限制。对于线性回归模型，使用L1正则化的模型建叫做Lasso回归，使用L2正则化的模型叫做Ridge回归（岭回归）。下图是Python中Lasso回归的损失函数，式中加号后面一项α||w||1即为L1正则化项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
